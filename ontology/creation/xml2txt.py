# xml2txt
# module to create a fielded text file from an xml (patent) file
# top level call: patents_xml2txt(patent_path, lang)

from lxml import etree
import os
import pdb
import sys

# path to include Marc's code
sys.path.append("/home/j/corpuswork/fuse/code/patent-classifier")
from utils.docstructure.main import Parser

def xml2txt_dir(xml_parser, source_path, target_path, ds_text_path, ds_tags_path , ds_fact_path, ds_sect_path):
    for file in os.listdir(source_path):
        source_file = source_path + "/" + file
        target_file = target_path + "/" + file
        ds_text_file = ds_text_path + "/" + file
        ds_tags_file = ds_tags_path + "/" + file
        ds_fact_file = ds_fact_path + "/" + file
        ds_sect_file = ds_sect_path + "/" + file
        print "[xml2txt_dir]from %s to %s" % (source_file, target_file)
        #p1 = Patent(source_file, target_file)
        # xml_file, text_file, tags_file, fact_file, sect_file, onto_file)
        xml_parser.create_ontology_creation_input(source_file, ds_text_file, ds_tags_file , ds_fact_file, ds_sect_file, target_file)

def test():
    xml_parser = Parser()
    parser.language = "ENGLISH" 
    #parser.language = "GERMAN" 
    #parser.language = "CHINESE" 

    source_path = "/home/j/anick/fuse/data/patents/en_test/xml"
    target_path = "/home/j/anick/fuse/data/patents/en_test/pickle"
    ds_text_path = "/home/j/anick/fuse/data/patents/en_test/ds_text"
    ds_tags_path = "/home/j/anick/fuse/data/patents/en_test/ds_tags"
    ds_fact_path = "/home/j/anick/fuse/data/patents/en_test/ds_fact"
    ds_sect_path = "/home/j/anick/fuse/data/patents/en_test/ds_sect"
    xml2txt_dir(xml_parser, source_path, target_path, ds_text_path, ds_tags_path, ds_fact_path, ds_sect_path)

# run xml doc analysis for lang (en, de, cn)
# eg. xml2txt.patents_xml2txt("/home/j/anick/fuse/data/patents", "en")
# eg. xml2txt.patents_xml2txt("/home/j/anick/fuse/data/patents", "de")
def patents_xml2txt(patent_path, lang):
    xml_parser = Parser()
    xml_parser.onto_mode = True
    start_year = 1980
    end_year = 2012
    if lang == "en":
        xml_parser.language = "ENGLISH"
        print "[patents_xml2txt]xml_parser.language: %s" % xml_parser.language
        
    elif lang == "de":
        xml_parser.language = "GERMAN"
        print "[patents_xml2txt]xml_parser.language: %s" % xml_parser.language
        start_year = 1980
        end_year = 2012
    elif lang == "cn":
        xml_parser.language = "CHINESE"
        print "[patents_xml2txt]xml_parser.language: %s" % xml_parser.language
        start_year = 1987
        end_year = 2012

    lang_path = patent_path + "/" + lang

    
    # create the year list and process those docs
    l_year = [] 
    for year in range(start_year, end_year):
        year = str(year)

        source_path = lang_path + "/xml" + "/" + year
        target_path = lang_path + "/txt" + "/" + year
        ds_text_path = lang_path + "/ds_text" + "/" + year
        ds_tags_path = lang_path + "/ds_tags" + "/" + year
        ds_fact_path = lang_path + "/ds_fact" + "/" + year
        ds_sect_path = lang_path + "/ds_sect" + "/" + year
        xml2txt_dir(xml_parser, source_path, target_path, ds_text_path, ds_tags_path, ds_fact_path, ds_sect_path)
        
        
"""
def test_pm():
    dir = "/home/j/anick/fuse/data/pubmed"
    file = "pubmed_lines.txt"
    output_file = "/home/j/anick/fuse/data/pubmed/chunks.txt"
    #file = "pubmed_lines_test_1.txt"
    # create a chunker schema instance
    cs = sdp.chunker_tech()
    # create tagger instance
    tagger = sdp.STagger("english-caseless-left3words-distsim.tagger") 

    process_patent_sent_file(dir, file, tagger, cs, output_file)



# process file generated by Olga from pubmed titles and abstracts
def process_pubmed_lines_file(pubmed_file, tagger, cs):
    s_pm = open(pubmed_file)
    for line in s_pm:
        line= line.strip("\n")
        fields = line.split("\t")
        
    s_pm.close()
"""
